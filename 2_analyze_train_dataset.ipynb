{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from matplotlib import pyplot as plt\n",
    "import my_funcs as mf\n",
    "import my_nn as nn\n",
    "\n",
    "# With these 2 lines you can modify my_funcs propahgate the changes here\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# Custom plot layout\n",
    "plt.rcParams[\"figure.facecolor\"] = \"white\"\n",
    "# To use black (auto formatter on the notebook): /opt/anaconda3/envs/plus2/bin/pip install nb_black\n",
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "final_dataset = \"data_yoochoose/final_df.dat\"\n",
    "# Parameters\n",
    "limit = None\n",
    "fig_folder = \"figs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = mf.load_file(\n",
    "    final_dataset, limit=limit, to_be_sorted=False, index_col=0, header=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Safety checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final[\"is_buy\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mf.sanity_checks(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr = df_final.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "im = ax.matshow(df_corr)\n",
    "\n",
    "ax.set_xticks(np.arange(len(df_final.columns)))\n",
    "ax.set_yticks(np.arange(len(df_final.columns)))\n",
    "ax.set_xticklabels(df_final.columns)\n",
    "ax.set_yticklabels(df_final.columns)\n",
    "\n",
    "# Rotate the tick labels and set their alignment.\n",
    "plt.setp(ax.get_xticklabels(), rotation=45)\n",
    "fig.colorbar(im)\n",
    "# Loop over data dimensions and create text annotations.\n",
    "for i in range(df_corr.shape[0]):\n",
    "    for j in range(df_corr.shape[1]):\n",
    "        text = ax.text(\n",
    "            j, i, round(df_corr.iloc[i, j], 2), ha=\"center\", va=\"center\", color=\"w\"\n",
    "        )\n",
    "\n",
    "ax.set_title(\"Correlation matrix\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = [\n",
    "    \"total_clicks\",\n",
    "    \"total_items\",\n",
    "    \"total_cats\",\n",
    "    \"max_dwell\",\n",
    "    \"mean_dwell\",\n",
    "    \"total_duration\",\n",
    "    \"click_rate\",\n",
    "    \"cat_most_viewed_n_times\",\n",
    "    \"cat_most_viewed\",\n",
    "    \"item_most_viewed_n_times\",\n",
    "    \"item_most_viewed\",\n",
    "    \"cat_views_freqs\",\n",
    "    \"item_views_freqs\",\n",
    "    \"item_buys_freqs\",\n",
    "]\n",
    "d_val = {\n",
    "    \"total_clicks\": {\"range\": (0, 200), \"bins\": 20},\n",
    "    \"total_items\": {\"range\": (0, 200), \"bins\": 20},\n",
    "    \"total_cats\": {\"range\": (0, 60), \"bins\": 20},\n",
    "    \"max_dwell\": {\"range\": (0, 60), \"bins\": 20},\n",
    "    \"mean_dwell\": {\"range\": (0, 60), \"bins\": 20},\n",
    "    \"total_duration\": {\"range\": (0, 1200), \"bins\": 20},\n",
    "    \"click_rate\": {\"range\": (0, 35), \"bins\": 20},\n",
    "    \"cat_most_viewed_n_times\": {\"range\": (0, 350), \"bins\": 20},\n",
    "    \"cat_most_viewed\": {\"range\": (0, 200), \"bins\": 20},\n",
    "    \"item_most_viewed_n_times\": {\"range\": None, \"bins\": 20},\n",
    "    \"item_most_viewed\": {\"range\": (0, 200), \"bins\": 20},\n",
    "    \"cat_views_freqs\": {\"range\": (0, 200), \"bins\": 20},\n",
    "    \"item_views_freqs\": {\"range\": None, \"bins\": 20},\n",
    "    \"item_buys_freqs\": {\"range\": None, \"bins\": 20},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in feature_columns:\n",
    "    n_uniq = len(df_final[col].unique())\n",
    "    print(f\"{col} has {n_uniq} unique values.\")\n",
    "    plt.hist(\n",
    "        df_final[df_final[\"is_buy\"] == 0][col],\n",
    "        label=\"not_buy\",\n",
    "        alpha=0.3,\n",
    "        density=True,\n",
    "        range=d_val[col][\"range\"],\n",
    "        bins=d_val[col][\"bins\"],\n",
    "    )\n",
    "    plt.hist(\n",
    "        df_final[df_final[\"is_buy\"] == 1][col],\n",
    "        label=\"buy\",\n",
    "        alpha=0.3,\n",
    "        density=True,\n",
    "        range=d_val[col][\"range\"],\n",
    "        bins=d_val[col][\"bins\"],\n",
    "    )\n",
    "    plt.xlabel(col)\n",
    "    plt.yscale(\"log\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.savefig(fig_folder + \"/2fin_h_\" + col + \".png\", bbox_inches=\"tight\", dpi=300)\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### POSSIBLE IMPROVEMENTS\n",
    "### Cap vars above 5 sigma\n",
    "### item_most_viewed_n_times and cat_most_viewed_n_times should be categorical\n",
    "### Remove period of time here there is no buy? (look at step0)\n",
    "### Add a DateTime start period. A float for period of the year, another for period of the month, another for the dat of the week, and the hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alf = nn.MlpHelper(\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"is_buy\"\n",
    "alf.load_dataset(\n",
    "    df=df_final, feature_columns=feature_columns, label=label, scale_dataset=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [20, 20, 15]\n",
    "alf.build_model(\n",
    "    layers=layers,\n",
    "    input_dim=len(feature_columns),\n",
    "    activation=\"relu\",\n",
    "    lr=0.01,\n",
    "    dropout_perc=0.5,\n",
    "    model_type=\"mlp\",\n",
    "    l1=0.0,\n",
    "    l2=0.0,\n",
    ")\n",
    "alf.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "w0 = df_final[df_final[\"is_buy\"] == 1].shape[0] / (\n",
    "    df_final.shape[0]\n",
    ")  # n(1)/tot = 0.05510388466516154\n",
    "w1 = df_final[df_final[\"is_buy\"] == 0].shape[0] / (\n",
    "    df_final.shape[0]\n",
    ")  # n(0)/tot = 0.9448961153348384\n",
    "alf.train_and_validate(\n",
    "    epochs=10,\n",
    "    batch_size=50,\n",
    "    class_weight={0: w0, 1: w1},\n",
    "    test_perc=10,\n",
    "    create_split=True,\n",
    "    train_index=None,\n",
    "    test_index=None,\n",
    "    lauc_fct=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alf.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alf.predict(alf.test_X, batch_size=50, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alf.compute_metrics(alf.test_Y, alf.predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alf.print_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alf.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.plot(\n",
    "    alf.metrics[\"laucs\"].keys(), list(alf.metrics[\"laucs\"].values()), label=\"model\"\n",
    ")\n",
    "plt.plot([0, 1], [0, 1], label=\"random\")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
